/**
 * Tool: extractClientInfo
 *
 * Extrai informa√ß√µes estruturadas do cliente usando GPT-4o
 * com structured output e valida√ß√£o via Zod
 *
 * Integra√ß√£o LangSmith: traceable para observabilidade
 *
 * Refer√™ncia: PRD RF-002 (linhas 56-77)
 */

import OpenAI from "openai"
import {
  traceable,
  createTracedOpenAI,
  addRunMetadata,
  WORKFLOW_STEP_NAMES
} from "@/lib/monitoring/langsmith-setup"
import {
  ClientInfoSchema,
  PartialClientInfoSchema,
  calculateCompleteness,
  type PartialClientInfo
} from "./schemas/client-info-schema"
import {
  parseClientInfo,
  detectMissingFields,
  getNextFieldToCollect,
  mergeClientInfo,
  validateClientInfoComplete,
  validateBusinessRules
} from "./validators/missing-fields-detector"
import {
  EXTRACTION_SYSTEM_PROMPT,
  EXTRACTION_MODEL_CONFIG,
  buildExtractionPrompt,
  getModelParams
} from "./prompts/extraction-prompts"
import type {
  ExtractClientInfoParams,
  ExtractClientInfoResponse
} from "./types"

/**
 * Implementa√ß√£o interna da extra√ß√£o de informa√ß√µes do cliente
 * Envolvida por traceable para observabilidade LangSmith
 */
async function extractClientInfoInternal(
  params: ExtractClientInfoParams,
  apiKey: string,
  model?: string
): Promise<ExtractClientInfoResponse> {
  const modelToUse = model || EXTRACTION_MODEL_CONFIG.model
  console.log("[extract-client-info] ========================================")
  console.log("[extract-client-info] üìã extractClientInfo called")
  console.log(
    "[extract-client-info] üì® Messages count:",
    params.messages?.length || 0
  )
  console.log(
    "[extract-client-info] üìù Has current info:",
    !!params.currentInfo
  )

  // Adicionar metadata ao trace atual
  addRunMetadata({
    messageCount: params.messages?.length || 0,
    hasCurrentInfo: !!params.currentInfo,
    model: modelToUse
  })

  try {
    // 1. Configurar OpenAI client com tracing autom√°tico
    console.log("[extract-client-info] üîß Configuring OpenAI client...")
    const openai = createTracedOpenAI({ apiKey })

    // 2. Construir prompt com hist√≥rico de conversa
    const messages = buildExtractionPrompt(params.messages)

    // 3. Adicionar instru√ß√£o final para extrair
    messages.push({
      role: "user",
      content:
        "Com base na conversa acima, extraia todas as informa√ß√µes dispon√≠veis do cliente em formato JSON estruturado. Se alguma informa√ß√£o obrigat√≥ria estiver faltando, retorne null para esse campo."
    })

    // 4. Chamar modelo com structured output
    console.log("[extract-client-info] ü§ñ Calling model:", modelToUse)
    const response = await openai.chat.completions.create({
      model: modelToUse,
      messages: messages,
      ...getModelParams(modelToUse, {
        temperature: EXTRACTION_MODEL_CONFIG.temperature,
        maxTokens: EXTRACTION_MODEL_CONFIG.maxTokens
      }),
      response_format: EXTRACTION_MODEL_CONFIG.responseFormat
    })

    console.log("[extract-client-info] ‚úÖ GPT-4o response received:", {
      tokensUsed: response.usage?.total_tokens,
      finishReason: response.choices[0]?.finish_reason
    })

    // 5. Extrair resposta
    const rawResponse = response.choices[0]?.message?.content

    if (!rawResponse) {
      console.error("[extract-client-info] ‚ùå GPT-4o returned empty response")
      throw new Error("GPT-4o n√£o retornou resposta v√°lida")
    }

    console.log(
      "[extract-client-info] üìÑ Raw response length:",
      rawResponse.length
    )

    // 6. Parse e valida√ß√£o
    console.log("[extract-client-info] üîç Parsing response...")
    const parseResult = parseClientInfo(rawResponse)

    if (!parseResult.success || !parseResult.data) {
      // Se n√£o h√° currentInfo, √© primeira intera√ß√£o - retornar pergunta inicial ao inv√©s de erro
      if (!params.currentInfo) {
        console.log(
          "[extract-client-info] ‚ö†Ô∏è Validation failed on first interaction, returning initial question"
        )
        const initialQuestion = await generateInitialQuestion(
          openai,
          modelToUse
        )
        return {
          clientInfo: {},
          missingFields: ["idade", "cidade", "estado", "or√ßamento mensal"],
          isComplete: false,
          completeness: 0,
          nextQuestion: initialQuestion
        }
      }

      // Se j√° tem currentInfo, significa que extra√ß√£o falhou - lan√ßar erro
      throw new Error(
        `Erro ao validar resposta: ${parseResult.errors?.join(", ")}`
      )
    }

    let clientInfo = parseResult.data || {}

    // 7. Merge com informa√ß√µes existentes (se houver)
    if (params.currentInfo && Object.keys(params.currentInfo).length > 0) {
      clientInfo = mergeClientInfo(params.currentInfo, clientInfo)
    }

    // 8. Detectar campos faltantes
    const missingFields = detectMissingFields(clientInfo)
    const missingFieldLabels = missingFields.map(f => f.label)

    // 9. Verificar se est√° completo
    const isComplete = validateClientInfoComplete(clientInfo)

    // 10. Calcular completude
    const completeness = calculateCompleteness(clientInfo)

    // 11. Gerar pr√≥xima pergunta (se aplic√°vel)
    let nextQuestion: string | undefined

    if (!isComplete) {
      const nextField = getNextFieldToCollect(clientInfo)

      if (nextField) {
        nextQuestion = await generateNextQuestion(
          nextField.field,
          clientInfo,
          openai,
          modelToUse
        )
      }
    }

    // 12. Validar regras de neg√≥cio (warnings n√£o bloqueantes)
    const warnings = validateBusinessRules(clientInfo)

    // 13. Adicionar metadata
    const enrichedClientInfo: PartialClientInfo = {
      ...clientInfo,
      metadata: {
        extractedAt: new Date().toISOString(),
        schemaVersion: "1.0",
        completeness
      }
    }

    console.log("[extract-client-info] ‚úÖ Extraction complete:", {
      isComplete,
      completeness,
      missingFieldsCount: missingFieldLabels.length,
      hasNextQuestion: !!nextQuestion,
      warningsCount: warnings.length
    })

    return {
      clientInfo: enrichedClientInfo,
      missingFields: missingFieldLabels,
      isComplete,
      completeness,
      nextQuestion
    }
  } catch (error) {
    console.error("[extract-client-info] ‚ùå Error:", error)

    throw new Error(
      `Falha ao extrair informa√ß√µes do cliente: ${error instanceof Error ? error.message : String(error)}`
    )
  }
}

/**
 * Gera pr√≥xima pergunta contextual para coletar campo faltante
 *
 * @param field - Campo que precisa ser coletado
 * @param currentInfo - Informa√ß√µes j√° coletadas
 * @param openai - OpenAI client
 * @param model - Modelo a ser usado
 * @returns Pergunta natural e emp√°tica
 */
async function generateNextQuestion(
  field: string,
  currentInfo: PartialClientInfo,
  openai: OpenAI,
  model: string
): Promise<string> {
  // Se n√£o h√° NENHUM campo obrigat√≥rio preenchido, usar pergunta inicial consolidada
  const hasAnyRequired =
    currentInfo.age ||
    currentInfo.city ||
    currentInfo.state ||
    currentInfo.budget

  if (!hasAnyRequired) {
    console.log(
      "[generateNextQuestion] No required fields found, using consolidated initial question"
    )
    return generateInitialQuestion(openai, model)
  }

  // Perguntas ajustadas para quando j√° h√° dados parciais (tom "falta apenas X")
  const questionPrompts: Record<string, string> = {
    age: "S√≥ falta me dizer: quantos anos voc√™ tem?",
    city: "E em qual cidade voc√™ mora?",
    state: "Qual √© o estado? (sigla, tipo SP, RJ, MG...)",
    budget:
      "Por √∫ltimo, quanto voc√™ pode investir mensalmente no plano? (valor aproximado)",
    dependents:
      "Voc√™ vai incluir dependentes no plano? Se sim, pode me contar sobre eles?",
    preExistingConditions:
      "Voc√™ ou algu√©m da sua fam√≠lia tem alguma condi√ß√£o de sa√∫de pr√©-existente que eu deva saber?",
    medications: "Algu√©m faz uso de medicamentos de forma cont√≠nua? Quais?",
    preferences:
      "Tem alguma prefer√™ncia espec√≠fica de rede credenciada ou hospitais?"
  }

  // Retornar pergunta pr√©-definida se existir
  if (questionPrompts[field]) {
    return questionPrompts[field]
  }

  // Caso contr√°rio, gerar pergunta contextual com GPT
  try {
    const response = await openai.chat.completions.create({
      model: model,
      messages: [
        {
          role: "system",
          content:
            "Voc√™ √© um assistente emp√°tico que est√° coletando informa√ß√µes para recomenda√ß√£o de planos de sa√∫de. Gere uma pergunta natural e amig√°vel para coletar a informa√ß√£o solicitada."
        },
        {
          role: "user",
          content: `Preciso coletar a informa√ß√£o: "${field}". Informa√ß√µes j√° coletadas: ${JSON.stringify(currentInfo)}. Gere uma pergunta natural e emp√°tica.`
        }
      ],
      ...getModelParams(model, { temperature: 0.7, maxTokens: 100 })
    })

    return (
      response.choices[0]?.message?.content ||
      "Pode me fornecer mais algumas informa√ß√µes?"
    )
  } catch (error) {
    console.error("[generateNextQuestion] Error:", error)
    return "Pode me fornecer mais algumas informa√ß√µes?"
  }
}

/**
 * Gera pergunta inicial consolidada pedindo TODOS os campos obrigat√≥rios
 * de uma vez na primeira intera√ß√£o
 *
 * @param openai - OpenAI client
 * @param model - Modelo a ser usado
 * @returns Pergunta consolidada amig√°vel
 */
async function generateInitialQuestion(
  openai: OpenAI,
  model: string
): Promise<string> {
  const defaultQuestion = `Ol√°! Para encontrar os melhores planos de sa√∫de para voc√™, preciso de algumas informa√ß√µes b√°sicas:

üìã **Informa√ß√µes necess√°rias:**
- Sua **idade**
- **Cidade** e **estado** onde voc√™ mora
- **Or√ßamento mensal** dispon√≠vel para o plano

Voc√™ tamb√©m pode me contar se vai incluir **dependentes** (c√¥njuge, filhos, pais) ou se tem alguma **condi√ß√£o de sa√∫de** que eu deva considerar.

Pode compartilhar essas informa√ß√µes? Pode ser de forma natural, sem se preocupar com a ordem!`

  try {
    const response = await openai.chat.completions.create({
      model: model,
      messages: [
        {
          role: "system",
          content:
            "Voc√™ √© um assistente emp√°tico que coleta informa√ß√µes para recomenda√ß√£o de planos de sa√∫de. Gere uma pergunta inicial amig√°vel que pede TODOS os campos obrigat√≥rios de uma vez: idade, cidade, estado, or√ßamento mensal. Mantenha tom conversacional e emp√°tico. N√£o use emojis em excesso."
        },
        {
          role: "user",
          content:
            "Gere a pergunta inicial consolidada pedindo idade, cidade, estado e or√ßamento de forma natural e amig√°vel."
        }
      ],
      ...getModelParams(model, { temperature: 0.7, maxTokens: 250 })
    })

    return response.choices[0]?.message?.content || defaultQuestion
  } catch (error) {
    console.error("[generateInitialQuestion] Error:", error)
    return defaultQuestion
  }
}

/**
 * Cria schema de function calling para registro da tool no OpenAI
 *
 * Este schema √© usado quando a tool √© registrada como uma fun√ß√£o
 * que o GPT pode chamar durante a conversa
 */
export const extractClientInfoFunctionSchema: OpenAI.Chat.Completions.ChatCompletionTool =
  {
    type: "function",
    function: {
      name: "extractClientInfo",
      description:
        "Extrai informa√ß√µes estruturadas do cliente a partir da conversa para recomenda√ß√£o de planos de sa√∫de. Use quando o usu√°rio fornecer informa√ß√µes pessoais, m√©dicas ou de or√ßamento.",
      parameters: {
        type: "object",
        properties: {
          age: {
            type: "number",
            description: "Idade do titular do plano"
          },
          city: {
            type: "string",
            description: "Cidade onde o cliente mora"
          },
          state: {
            type: "string",
            description: "Sigla do estado (ex: SP, RJ, MG)"
          },
          budget: {
            type: "number",
            description: "Or√ßamento mensal dispon√≠vel em reais"
          },
          dependents: {
            type: "array",
            description: "Lista de dependentes a serem inclu√≠dos no plano",
            items: {
              type: "object",
              properties: {
                relationship: {
                  type: "string",
                  enum: ["spouse", "child", "parent", "other"],
                  description: "Rela√ß√£o do dependente com o titular"
                },
                age: {
                  type: "number",
                  description: "Idade do dependente"
                }
              },
              required: ["relationship", "age"]
            }
          },
          preExistingConditions: {
            type: "array",
            description: "Condi√ß√µes de sa√∫de pr√©-existentes declaradas",
            items: {
              type: "string"
            }
          },
          medications: {
            type: "array",
            description: "Medicamentos de uso cont√≠nuo",
            items: {
              type: "string"
            }
          },
          preferences: {
            type: "object",
            description: "Prefer√™ncias do cliente para o plano",
            properties: {
              networkType: {
                type: "string",
                enum: ["broad", "restricted"],
                description: "Tipo de rede credenciada preferida"
              },
              coParticipation: {
                type: "boolean",
                description: "Aceita planos com coparticipa√ß√£o"
              },
              specificHospitals: {
                type: "array",
                description: "Hospitais espec√≠ficos desejados",
                items: {
                  type: "string"
                }
              }
            }
          }
        },
        required: ["age", "city", "state", "budget"]
      }
    }
  }

// =============================================================================
// FUN√á√ÉO EXPORTADA COM TRACEABLE
// =============================================================================

/**
 * Tool principal para extra√ß√£o de informa√ß√µes do cliente
 * Envolvida com traceable para observabilidade LangSmith
 *
 * @param params - Par√¢metros incluindo mensagens e informa√ß√µes atuais
 * @param apiKey - OpenAI API key
 * @param model - Modelo a ser usado (default: EXTRACTION_MODEL_CONFIG.model)
 * @returns Informa√ß√µes extra√≠das, campos faltantes e status de completude
 */
export const extractClientInfo = traceable(
  async (
    params: ExtractClientInfoParams,
    apiKey: string,
    model?: string
  ): Promise<ExtractClientInfoResponse> => {
    return extractClientInfoInternal(params, apiKey, model)
  },
  {
    name: WORKFLOW_STEP_NAMES.EXTRACT_CLIENT_INFO,
    run_type: "chain",
    tags: ["health-plan", "step-1", "extraction"],
    metadata: {
      step: 1,
      description: "Extrai informa√ß√µes estruturadas do cliente usando GPT-4o"
    }
  }
)

/**
 * Wrapper simplificado para uso em API routes
 *
 * @param messages - Hist√≥rico de mensagens da conversa
 * @param apiKey - OpenAI API key
 * @param currentInfo - Informa√ß√µes j√° coletadas (opcional)
 * @returns ExtractClientInfoResponse
 */
export async function extractFromConversation(
  messages: Array<{ role: "user" | "assistant" | "system"; content: string }>,
  apiKey: string,
  currentInfo?: PartialClientInfo
): Promise<ExtractClientInfoResponse> {
  return extractClientInfo(
    {
      messages,
      currentInfo
    },
    apiKey
  )
}
